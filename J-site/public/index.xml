<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>J-site</title>
    <link>https://example.org/</link>
    <description>Recent content on J-site</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 02 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>New Chapter</title>
      <link>https://example.org/post/7/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/7/</guid>
      <description>&lt;p&gt;It’s been eight months since my last post — time really flies. During this period, I went through two major milestones: graduating and job hunting.&lt;/p&gt;&#xA;&lt;p&gt;The time right after graduation was both exciting and overwhelming. I wasn’t entirely sure which direction to take — I seriously considered switching paths, perhaps diving deeper into software or data-related roles. But after rounds of reflection and interviews, I decided to stick with what I know best. I accepted a role that leans more toward electrical engineering, continuing my work in wireless communication protocols. It feels like a natural extension of what I’ve been doing, and I believe there’s still a lot of depth to explore in this field.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Real Time ML</title>
      <link>https://example.org/post/6/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/6/</guid>
      <description>&lt;p&gt;One of my early ventures into MLOps involved working with a stock-price prediction system, which proved to be an excellent learning experience in modern ML infrastructure. The project leveraged a comprehensive tech stack: Kubernetes for orchestration, Apache Airflow for workflow management, Apache Spark for data processing, Kafka for real-time data streaming, and Cassandra for data storage. While the framework looked impressive and sophisticated, when I attempted to apply this architecture to my previous ML projects, I encountered a fundamental mismatch: this infrastructure was optimized for streaming data processing, whereas most of my projects dealt with batch machine learning tasks. And this also remind of what I thought of real-time ML.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some random thoughts on ML</title>
      <link>https://example.org/post/5/</link>
      <pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/5/</guid>
      <description>&lt;p&gt;As a PhD student in wireless communications (5G), my relationship with Machine Learning has been somewhat paradoxical. While I&amp;rsquo;ve been using various advanced algorithms, including deep learning and reinforcement learning in my research projects, my understanding mostly stayed at the framework level - knowing how to use algorithms without truly grasping ML for production.&#xA;That changed when I discovered Chip Huyen&amp;rsquo;s blog. What initially caught my attention was her unique approach to discussing Machine Learning - not just as a collection of algorithms and frameworks, but as a living, breathing field that intersects with real-world engineering challenges and career development.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Parallel &amp; Distributed Training/Inference of Deep Learning Models</title>
      <link>https://example.org/post/4/</link>
      <pubDate>Sun, 06 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/4/</guid>
      <description>&lt;h3 id=&#34;data-parallelism&#34;&gt;Data parallelism&lt;/h3&gt;&#xA;&lt;p&gt;One extreme scenario for data parallelism is when the entire model fits within the GPU memory and not enough space for data.&#xA;Same model will be deployed on multiple GPUs, though the inputs are different, the output will be gathered and dispatched to each GPU to update the model.&lt;/p&gt;&#xA;&lt;p&gt;Solution: nn.parallel.DistributedDataParallel, MPI+NCCL&lt;/p&gt;&#xA;&lt;h3 id=&#34;model-parallelism&#34;&gt;Model parallelism&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Vertical Split (Layer Parallelism):&lt;/strong&gt;&#xA;This refers to dividing the layers of a model across multiple GPUs. In this setup, each GPU is responsible for computing a different portion of the neural network (e.g., GPU 1 processes layer 1, GPU 2 processes layer 2, and so on). This is sometimes referred to as pipeline parallelism, where data is passed sequentially through each GPU as it progresses through the layers of the model.Usually combined with batch parallelism.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Familiar with the foundational transformer architecture</title>
      <link>https://example.org/post/3/</link>
      <pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/3/</guid>
      <description>&lt;h3 id=&#34;some-related-reading-materials&#34;&gt;Some related reading materials&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://medium.com/towards-data-science/the-math-behind-multi-head-attention-in-transformers-c26cba15f625&#34;&gt;The Math Behind Multi-Head Attention in Transformers&lt;/a&gt;&#xA;&lt;a href=&#34;https://medium.com/@geetkal67/attention-networks-a-simple-way-to-understand-self-attention-f5fb363c736d&#34;&gt;Attention Networks: A simple way to understand Self-Attention&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scalable AI infrastructure design and implementing.</title>
      <link>https://example.org/post/2/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/2/</guid>
      <description>&lt;h3 id=&#34;some-related-reading-materials&#34;&gt;Some Related Reading Materials&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://scalable-infrastructure.github.io/&#34;&gt;Course:Infrastructure for Advanced Analytics and Machine Learning&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/1duo/awesome-ai-infrastructures/&#34;&gt;Tech companies&amp;rsquo; AI infra&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://ganguly-04.medium.com/airflow-spark-s3-stitching-it-all-together-1acbfba67e33&#34;&gt;Basic reading + hands on - Airflow+Spark+S3+Amazon EMR&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Zzdragon66/stock-streaming-project&#34;&gt;Open source AI infra project - stock-streaming-project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;ai-infrastructure-workflow&#34;&gt;AI Infrastructure Workflow&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1-workflow-overview&#34;&gt;1. Workflow Overview&lt;/h4&gt;&#xA;&lt;p&gt;The workflow involves several stages to manage data effectively from various sources to actionable insights. Key stages include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extract (Data Source to Data Lake)&lt;/li&gt;&#xA;&lt;li&gt;Transform (Data Processing)&lt;/li&gt;&#xA;&lt;li&gt;Load to Data Warehouse&lt;/li&gt;&#xA;&lt;li&gt;Query &amp;amp; Analytics&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;2-extract-data-source-to-data-lake&#34;&gt;2. Extract (Data Source to Data Lake)&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Data Sources&lt;/strong&gt;: Raw data is extracted from:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Current main AI/ML engineer directions and corresponding requirements</title>
      <link>https://example.org/post/1/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/1/</guid>
      <description>&lt;p&gt;Here are some current directions in AI/ML and their corresponding requirements:&lt;/p&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s your modified list with dashes added:&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-narrative-videos-and-childrens-stories&#34;&gt;1. Narrative videos and children&amp;rsquo;s stories.&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Deep Learning:&lt;/strong&gt; Experience in neural networks, especially in applications related to text, audio, image, and video generation.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Ensemble Models:&lt;/strong&gt; Familiarity with combining multiple AI models for improved performance across different content types (e.g., text-to-text, text-to-audio).&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Natural Language Processing (NLP):&lt;/strong&gt; Skills in developing chatbots and recommendation systems.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
