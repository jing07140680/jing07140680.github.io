---
date: 2024-09-23
description: "The Grand Hall"
featured_image: "" 
tags: ["scene"]
title: "Familiar with the foundational transformer architecture"
---
### Some related reading materials
[The Math Behind Multi-Head Attention in Transformers](https://medium.com/towards-data-science/the-math-behind-multi-head-attention-in-transformers-c26cba15f625)
[Attention Networks: A simple way to understand Self-Attention](https://medium.com/@geetkal67/attention-networks-a-simple-way-to-understand-self-attention-f5fb363c736d)
